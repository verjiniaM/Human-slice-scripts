{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have an installable package now\n",
    "# \n",
    "# pip install -e '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/code/Human-slice-scripts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ephys_analysis import funcs_sorting as sort\n",
    "from ephys_analysis import funcs_human_characterisation as hcf\n",
    "from ephys_analysis import funcs_plotting_raw_traces\n",
    "from ephys_analysis import funcs_con_screen as con_param\n",
    "from ephys_analysis import funcs_plot_intrinsic_props as plot_intr\n",
    "\n",
    "# this is only for 11.16 because the excel can't be open normally for whatever reason\n",
    "        \n",
    "def get_OP_metadata(human_dir, OP, patcher, path_wd):\n",
    "        \n",
    "    work_dir = sort.get_work_dir(human_dir, OP, patcher)\n",
    "    file_list = sort.get_sorted_file_list(work_dir)\n",
    "    filenames = sort.get_abf_files(file_list)\n",
    "    jsons= sort.get_json_files(file_list)\n",
    "\n",
    "    df_rec = pd.read_excel(path_wd, header=1)\n",
    "\n",
    "    slice_indx, def_slice_names, indices_dict = sort.sort_protocol_names(file_list, df_rec)\n",
    "\n",
    "    if OP + '_indices_dict.json' in jsons:\n",
    "        indices_dict = sort.from_json(work_dir, OP, '_indices_dict.json')\n",
    "    else:\n",
    "        sort.to_json(work_dir, OP, '_indices_dict.json', indices_dict)\n",
    "\n",
    "    slice_names = sort.fix_slice_names(def_slice_names, slice_indx)\n",
    "    return work_dir, filenames, indices_dict, slice_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      manual inputs\n",
    "human_dir = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/data/mouse/'\n",
    "\n",
    "OP = '2023.11.14_CA1_subiculum'\n",
    "tissue_source = ''\n",
    "inj = 'full'\n",
    "age = ''\n",
    "patcher = ''\n",
    "\n",
    "# here you have to enter the date and time of the recording m–∞nually\n",
    "# in the comments are the possible entries \n",
    "# active_chans_meta = [{'OP_time': [\"2023-11-13 08:44:00\"], # 13.11 8:44, 14.11 08:31, 16.11 - 09:16\n",
    "#                       'slices' :['S1', 'S2', 'S3'],\n",
    "#                       'vc_files': [0, 9, 20],                      \n",
    "#                       'active_chans': [[1,5,6,8],\n",
    "#                                        [2, 6, 7, 8],\n",
    "#                                        [6, 7, 8]]}]\n",
    "\n",
    "# active_chans_meta = [{'OP_time': [\"2023-11-14 08:31:00\"], # 13.11 8:44, 14.11 08:31, 16.11 - 09:16\n",
    "#                       'slices' : ['S1', 'S1_2','S2', 'S2_2'],\n",
    "#                       'vc_files': [0, 8, 16, 28],                      \n",
    "#                       'active_chans': [[2, 4, 7, 8],\n",
    "#                                        [1, 2, 8],\n",
    "#                                        [1, 2, 8],\n",
    "#                                        [1, 2, 6]]}]\n",
    "\n",
    "active_chans_meta = [{'OP_time': [\"2023-11-16 09:16:00\"], # 13.11 8:44, 14.11 08:31, 16.11 - 09:16\n",
    "                      'slices' :['S1', 'S2', 'S2_2', 'S4'],\n",
    "                      'vc_files': [0, 10, 20, 36, 41],                      \n",
    "                      'active_chans': [[7, 8],\n",
    "                                       [4, 6, 7, 8],\n",
    "                                       [1, 2, 4, 7, 8],\n",
    "                                       [4, 7, 8]]}]                    \n",
    "                                         \n",
    "                                                                                                                    \n",
    "# for other non-error folders\n",
    "work_dir, filenames, indices_dict, slice_names = sort.get_OP_metadata(human_dir, OP, patcher, 'old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3006259031.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[26], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    dir_plots = sort.make_dir_if_not_existing_dir, 'plots')\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# #creating a dir to save plots and data_tables (if not existing)\n",
    "dir_plots = sort.make_dir_if_not_existing_dir, 'plots')\n",
    "sort.make_dir_if_not_existing_dir, 'data_tables')\n",
    "\n",
    "#      check if the traces dir is empty and only then plot the middle sweep for each filename\n",
    "sort.plot_trace_if_not_done(work_dir, dir_plots, filenames)\n",
    "\n",
    "cortex_out_time = sort.get_datetime_from_input(\n",
    "    \n",
    "    \n",
    "     \n",
    "     \n",
    "                                   \n",
    "                                                                 active_chans_meta[0]['OP_time'][0])\n",
    "                                                                                            \n",
    "                                                                                           # creating the dataframe\n",
    "                                                                                           df_OP = pd.DataFrame(columns=['filename', 'slice', 'cell_ch',\n",
    "                                                                                           'hrs_after_slicing', 'Rs', 'Rin', 'resting_potential', 'max_spikes',\n",
    "                                                             'Rheobase', 'AP_heigth', 'TH', 'max_depol', 'max_repol', 'membra_time_constant_tau',\n",
    "                              'capacitance', 'AP_halfwidth', 'cell_type', 'inputs', 'AP_in_input', 'comment'])\n",
    "\n",
    "for i in range(len(indices_dict['vc'])):\n",
    "    vc = indices_dict['vc'][i]\n",
    "    vm = indices_dict['resting'][i]\n",
    "    char = indices_dict['characterization'][i]\n",
    "\n",
    "    slic = slice_names[vc]\n",
    "\n",
    "    filename_vc = work_dir + filenames[vc]\n",
    "    filename_vm = work_dir + filenames[vm]\n",
    "filename_char = work_dir + filenames[char]\n",
    "\n",
    "time_after_op = sort.get_time_after_OP(filename_char, cortex_out_time)\n",
    "\n",
    "active_channels = active_chans_meta[0]['active_chans'][i]\n",
    "\n",
    "    cell_IDs = hcf.get_cell_IDs(filename_char, slic, active_channel)\n",
    "                               time_after_op = sor.get_time_after_\n",
    "                                                         Rs, Rin = hcf.get_acess_resistance(\n",
    "                                                         RMPs = hcf.get_RMP(ilename_vm, acti\n",
    "                                                     \n",
    "                                                    \n",
    "            params1_df = pd.DatFrame({'filename==\n",
    "                                                    \n",
    "            'hrs_after_slicing': time_after_op,==\n",
    "                              'Rs': Rs, 'Rin': Rin, =\n",
    "        'resting_potential': RMPs})==\n",
    "=\n",
    "         ==\n",
    "    inj = hcf.get_ij_current_stepsfilename_char)=\n",
    "         ==\n",
    "charact_params = hcf.all_chracerization_params(=\n",
    "         filename_char, active_channels, inj, onset=1000, offset=11000)\n",
    "df_char = pd.DataFrame.from_dit(charact_params)=\n",
    " \n",
    "    \n",
    "df_to_add = pd.concat([params1df, df_char], axis=1)\n",
    "    d f_OP = pd.concat([d=\n",
    "    f_OP.loc[:], df_to_add]).reset_index(drop=True)\n",
    "\n",
    "                     \n",
    "     # plotting function=\n",
    "    \n",
    "plotting_funcs.plot_vc_holding(filename_vc, active_\n",
    "     cha\n",
    "                     nnels)\n",
    "     plotting_funcs.plots_=\n",
    "    for_charact_file(filename_char, active_channels, inj)\n",
    "\n",
    "     \n",
    "                     \n",
    "O Ps = pd.Series(OP).repea=\n",
    "    t(len(df_OP))\n",
    "researcher = pd.Series('Verji').repeat(len(df_OP))\n",
    "     \n",
    "                     \n",
    "s eries_df = pd.DataFrame(=\n",
    "    {'OP': OPs, 'patcher': researcher}).reset_index(drop=True)\n",
    "\n",
    "     \n",
    "                     \n",
    "d f_intrinsic = pd.concat([series_df, df_OP], axis=1)\n",
    "\n",
    "df_intrinsic.to_excel(work_dir + 'data_tables/' + O\n",
    "     P +\n",
    "                      '_Intrinsic_and_synaptic_properties.xlsx', index=False)\n",
    "# df_intrinsic.to_csv(work_dir + 'data_tables/' + OP[:-1] + '_Intrinsic_and_synaptic_properties.csv')\n",
    "\n",
    "print('Intrinsic properties DataFrame for  ' + OP +\n",
    "      ' saved successfully. ' + '\\n' + 'Exclude recordings if necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      connectivity screen analysis\n",
    "con_sccreen_connected_chans = active_chans_meta[1]\n",
    "\n",
    "for k, slic in enumerate(con_sccreen_connected_chans['con_screen_IC_file_indices']):\n",
    "    post_cells = con_sccreen_connected_chans['post_chans_VC'][k]\n",
    "    for cell in post_cells:\n",
    "        fn = work_dir + filenames[slic]\n",
    "        plotting_funcs.plot_trace(fn, 5, cell)\n",
    "\n",
    "\n",
    "#      the following is a quick script to get a plot of the characterization and the input file\n",
    "\n",
    "# fn_indx = 22\n",
    "# active_channels = [1]\n",
    "#      swp = 9\n",
    "channels = [1,               2   ,   4,  7, 8]\n",
    "indx_input_screen_fn = 32\n",
    "slic = 'S2_2'\n",
    "#      plotting_funcs.plot_trace(work_dir + filenames[fn_indx], swp, chan)\n",
    "\n",
    "\n",
    "fn_input_screen = work_dir + filenames[indx_input_screen_fn]\n",
    "con_screen_data = hcf.load_traces(fn_input_screen)\n",
    "\n",
    "\n",
    "for chan in channels:\n",
    "    chan_name = 'Ch' + str(chan)\n",
    "    pre_sig = con_screen_data[chan_name][0]\n",
    "    vmO = np.mean(pre_sig, axis=1)    from\n",
    "\n",
    "    fig,      ax = plt.subplo t s ( 1 , =(5,      3))\n",
    "    for i in range(np.shape(pre_sig)[1]):\n",
    "        ax.plot(pre_sig[10_000:17_000,      i], =c======3.=====\n",
    "\n",
    "    ax.plot(vmO[10_000:17_000], c='green', alpha=1,\n",
    "           ==\n",
    "            ==\n",
    "             ==\n",
    "             ==\n",
    "             ==\n",
    "              lw=1.5, label='average input in TTX')\n",
    "    #  ax.set_title(filenames[indx_input_screen_fn] + ' ' + chan_name)\n",
    "    # ax.set_axis_off()\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    a x.get_xaxis().set_visible(False)\n",
    "    a x.set_yticks([-60, -40, -20, 0, 20, 40])\n",
    "    a x.set_ylabel('mV')\n",
    "    #  fig.legend()\n",
    "    #  plt.savefig('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/mouse/ca1-sub-channorhodopsin_mice/Calb-CreSubiculum/inputs/legend_2' + '.jpg')\n",
    "    # plt.savefig('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/mouse/ca1-sub-channorhodopsin_mice/Calb-CreSubiculum/inputs/TTX_4AP_fn_' + str(indx_input_screen_fn) + '_' +slic + 'Ch.' + str(chan) + '.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
