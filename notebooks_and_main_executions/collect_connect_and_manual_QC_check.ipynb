{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect info from all connectivity jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import ephys_analysis.funcs_sorting as sort\n",
    "import json\n",
    "import numpy as np\n",
    "import ephys_analysis.funcs_for_results_tables as get_results\n",
    "import ephys_analysis.funcs_plotting_raw_traces as funcs_plotting_raw_traces\n",
    "import PyQt5\n",
    "\n",
    "def repatch_duplicates(df, ID_column):\n",
    "    not_repatched_cells = []\n",
    "    for cell in df[ID_column].unique():\n",
    "        if len(df[df[ID_column] == cell]) < 2:\n",
    "            print('No repatch partner for ' + cell)\n",
    "            not_repatched_cells.append(cell)\n",
    "\n",
    "    duplicates = []\n",
    "    for cell in df[ID_column].unique():\n",
    "        if len(df[df[ID_column] == cell]) > 2:\n",
    "            print('Repeated con_IDs' + cell)\n",
    "            duplicates.append(cell)\n",
    "    return not_repatched_cells, duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update to the latest df_intr, if needed\n",
    "df_intr = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/intrinsic_properties/2024-11-27_collected.xlsx')\n",
    "df_intr = df_intr.sort_values('OP')\n",
    "df_intr = df_intr[df_intr.hrs_incubation != 0]\n",
    "\n",
    "# create OP and age dictionary, to cross check info \n",
    "op_age_dict, op_hrs_incubation = {}, {}\n",
    "for OP in df_intr.OP.unique():\n",
    "    op_age_dict[OP] = float(np.mean(df_intr.patient_age[df_intr.OP == OP]))\n",
    "    op_hrs_incubation[OP] = float(np.mean(df_intr.hrs_incubation[df_intr.OP == OP]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing in the intrinsic dataframe\n",
    "ops_add = ['OP231109', 'OP230704', 'OP220413', 'OP240516', 'OP220615', 'OP230417', 'OP230504']\n",
    "ages_add = [44, 16, 17, 27, 14, 4.5, 56]\n",
    "hrs_inc_add = [24, 3, 20, 0, 0, 0, 3]\n",
    "\n",
    "for g, op in enumerate(ops_add):\n",
    "    op_age_dict[op] = ages_add[g]\n",
    "    op_hrs_incubation[op] = hrs_inc_add[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_DIR = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/data/human/'\n",
    "PATHS = [HUMAN_DIR + 'data_verji/', HUMAN_DIR + 'data_rosie/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all con_screen metadata\n",
    "OPs, ages, patchers, fns, days, hrs_incubation, slices, treatments, pre_chans, post_chans = [], [], [], [], [], [], [], [], [], []\n",
    "for dir in PATHS:\n",
    "    op_dirs = [d for d in os.listdir(dir) if d.startswith('OP')]\n",
    "    if 'rosie' in dir:\n",
    "        patcher = 'Rosie'\n",
    "    else:\n",
    "        patcher = 'Verji'\n",
    "    for op_dir in op_dirs:\n",
    "        # lab_book_paths = glob.glob(f\"{dir + op_dir}/*.xlsx\")\n",
    "        # lab_book = pd.read_excel([f for f in lab_book_path2 if not f.startswith(f\"{dir + op_dir}/~$\")][0])\n",
    "        con_screen_jsons = glob.glob(f\"{dir + op_dir}/*con_screen_only.json\")\n",
    "        if len(con_screen_jsons) < 1:\n",
    "            print('no con_screen_json for ' + op_dir)\n",
    "            continue\n",
    "        else:\n",
    "            con_screen_json = json.load(open(con_screen_jsons[0]))[0]\n",
    "        file_list = sort.get_abf_files(sorted(os.listdir(dir + op_dir)))\n",
    "        for i, slic in enumerate(con_screen_json['slices']):\n",
    "            if 'pre_chans' not in con_screen_json.keys():\n",
    "                print('no connections for OP' + con_screen_json['OP_time'][:-6])\n",
    "                continue\n",
    "            if len(con_screen_json['pre_chans']) == 0:\n",
    "                print('no connections for OP' + con_screen_json['OP_time'][:-6])\n",
    "            else:\n",
    "                for j, pre_chan in enumerate(con_screen_json['pre_chans'][i]):\n",
    "                    OP = 'OP' + con_screen_json['OP_time'][:-6]\n",
    "                    OPs.append(OP)\n",
    "                    ages.append(op_age_dict[OP])\n",
    "                    fns.append(file_list[con_screen_json['con_screen_file'][i]])\n",
    "                    if len(slic) > 2:\n",
    "                        days.append('D2')\n",
    "                        hrs_incubation.append(op_hrs_incubation[OP])\n",
    "                    else:\n",
    "                        days.append('D1')\n",
    "                        hrs_incubation.append(0)\n",
    "                    slices.append(slic)\n",
    "                    treatments.append(con_screen_json['treatment'][i])\n",
    "                    pre_chans.append(pre_chan)\n",
    "                    post_chans.append(con_screen_json['post_chans'][i][j])\n",
    "                    patchers.append(patcher)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save dataframe\n",
    "con_screen_df = pd.DataFrame({'OP' :OPs, 'patient_age': ages, 'patcher' : patchers, 'filename': fns, \\\n",
    "                              'day': days, 'hrs_incubation': hrs_incubation, 'slice': slices, \\\n",
    "                                'treatment': treatments, 'pre_chans': pre_chans, 'post_chans': post_chans })\n",
    "\n",
    "del OPs, ages, fns, days, hrs_incubation, slices, treatments, pre_chans, post_chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_screen_df.to_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/con_screen_collected.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for the intrinsic properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all intrinsic metadata\n",
    "OPs, ages, fns, days, hrs_incubation, slices, treatments, active_chans, patchers = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "OP_no_connectivity = ['OP231207', 'OP240208', 'OP231005', 'OP230914', 'OP230126', 'OP221116', 'OP210304', 'OP201020']\n",
    "for dir in PATHS:\n",
    "    if 'rosie' in dir:\n",
    "        patcher = 'Rosie'\n",
    "    else:\n",
    "        patcher = 'Verji'\n",
    "    op_dirs = [d for d in os.listdir(dir) if d.startswith('OP')]\n",
    "    for op_dir in op_dirs:\n",
    "        if op_dir in OP_no_connectivity:\n",
    "            continue\n",
    "        meta_ = glob.glob(f\"{dir + op_dir}/*meta_active_chans.json\")\n",
    "        if len(meta_) < 1:\n",
    "            print('no meta_active_chans for ' + op_dir)\n",
    "            continue\n",
    "        else:\n",
    "            meta_active_chans = json.load(open(meta_[0]))[0]\n",
    "        file_list = sort.get_abf_files(sorted(os.listdir(dir + op_dir)))\n",
    "        for i, slic in enumerate(meta_active_chans['slices']):\n",
    "            # if 'active_chans' not in meta_active_chans.keys():\n",
    "            #     print('no recordings for OP' + op_dir)\n",
    "            #     continue\n",
    "            # if len(meta_active_chans['active_chans']) == 0:\n",
    "            #     print('no recordings for OP' + op_dir)\n",
    "            for j, chan in enumerate(meta_active_chans['active_chans'][i]):\n",
    "                OP = op_dir\n",
    "                OPs.append(OP)\n",
    "                ages.append(op_age_dict[OP])\n",
    "                fns.append(file_list[meta_active_chans['vc_files'][i]])\n",
    "                if len(slic) > 2:\n",
    "                    days.append('D2')\n",
    "                    hrs_incubation.append(op_hrs_incubation[OP])\n",
    "                else:\n",
    "                    days.append('D1')\n",
    "                    hrs_incubation.append(0)\n",
    "                slices.append(slic)\n",
    "                treatments.append(meta_active_chans['treatment'][i])\n",
    "                active_chans.append(chan)\n",
    "                patchers.append(patcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_active_chans_df = pd.DataFrame({'filename': fns, 'patcher': patchers,'OP' :OPs, 'patient_age': ages, \\\n",
    "                                    'day': days, 'hrs_incubation': hrs_incubation, \\\n",
    "                                      'slice': slices, 'treatment': treatments, 'chan': active_chans})\n",
    "\n",
    "del OPs, ages, fns, days, hrs_incubation, slices, treatments, active_chans, patchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the treatment a string\n",
    "# was a list in the older analysis versions\n",
    "new_tr = []\n",
    "for tr in all_active_chans_df.treatment:\n",
    "    if isinstance(tr, list):\n",
    "        new_tr.append(tr[0])\n",
    "    else:\n",
    "        new_tr.append(tr)\n",
    "all_active_chans_df['treatment'] = new_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/'\n",
    "all_active_chans_df = all_active_chans_df.sort_values(['OP', 'filename', 'chan'])\n",
    "all_active_chans_df.to_excel(save_dir + 'all_active_chans.xlsx')\n",
    "print('df saved to be completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check repatched cells and connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the intrinsic meta json collected df\n",
    "# df_all_cells = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/all_active_chans_filled_in.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take repatch only df\n",
    "df_all_repatched = df_all_cells[df_all_cells['repatch'] == 'yes']\n",
    "df_all_repatched.reset_index(inplace = True, drop = True)\n",
    "patcher_dict = {'Verji': 'vm',\n",
    "                'Rosie': 'rs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cell IDs\n",
    "cell_IDs = []\n",
    "for i, op in enumerate(df_all_repatched.OP):\n",
    "    initials = patcher_dict[df_all_repatched.patcher[i]]\n",
    "\n",
    "    if df_all_repatched.day[i] == 'D1':\n",
    "        slic = df_all_repatched.slice[i]\n",
    "        ch = str(int(df_all_repatched.chan[i]))\n",
    "    else:\n",
    "        slic = df_all_repatched.slice[i][:2]\n",
    "        ch = str(int(df_all_repatched.repatched_ch_from_D1[i]))\n",
    "        \n",
    "    cell_IDs.append(initials + '_' + op[2:] + '_'  + slic + '_' + ch)\n",
    "df_all_repatched['cell_IDs'] = cell_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num unique cell_IDs: ' + str(len(df_all_repatched['cell_IDs'].unique())))\n",
    "print('all repatched cells : ' + str(len(df_all_repatched)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for not repatched cells and duplicates \n",
    "not_repatched_cells, duplicates = repatch_duplicates(df_all_repatched, 'cell_IDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_cells.to_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/all_active_chans_filled_in.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare con_screen and intrinsic to find repatched connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_screen_df = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/con_screen_collected.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patcher_dict = {'Verji': 'vm',\n",
    "                'Rosie': 'rs'}\n",
    "con_screen_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pre and post cell IDs\n",
    "pre_cell_IDs, post_cell_IDs = [], []\n",
    "for i, op in enumerate(con_screen_df.OP):\n",
    "    initials = patcher_dict[con_screen_df.patcher[i]]\n",
    "    slic = con_screen_df.slice[i]\n",
    "    pre_chan = con_screen_df.pre_chans[i]\n",
    "    post_chan = con_screen_df.post_chans[i]\n",
    "    pre_cell_IDs.append(initials + '_' + op[2:] + '_'  + slic + '_' + str(pre_chan))\n",
    "    post_cell_IDs.append(initials + '_' + op[2:] + '_'  + slic + '_' + str(post_chan))\n",
    "\n",
    "con_screen_df['pre_chan_IDs'] = pre_cell_IDs\n",
    "con_screen_df['post_chan_IDs'] = post_cell_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp cell_IDs repatched cells\n",
    "temp_IDs = []\n",
    "for k, op in enumerate(df_all_repatched.OP):\n",
    "    initials = patcher_dict[df_all_repatched.patcher[k]]\n",
    "    slic = df_all_repatched.slice[k]\n",
    "    ch = str(int(df_all_repatched.chan[k]))\n",
    "    temp_IDs.append(initials + '_' + op[2:] + '_'  + slic + '_' + ch)\n",
    "\n",
    "# Find duplicates\n",
    "seen = set()\n",
    "duplicates = []\n",
    "\n",
    "for item in temp_IDs:\n",
    "    if item in seen:\n",
    "        duplicates.append(item)\n",
    "    else:\n",
    "        seen.add(item)\n",
    "\n",
    "# Print the list of duplicates\n",
    "print(f\"Duplicates: {duplicates}\") # if none --> continue\n",
    "df_all_repatched['temp_IDs'] = temp_IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repatch = []\n",
    "for g, pre_cell in enumerate(pre_cell_IDs):\n",
    "    post_cell = post_cell_IDs[g]\n",
    "    if pre_cell in temp_IDs and post_cell in temp_IDs:\n",
    "        repatch.append('yes')\n",
    "    else:\n",
    "        repatch.append('no')\n",
    "con_screen_df['repatch'] = repatch\n",
    "\n",
    "print('num repatched connections ' + str(repatch.count('yes')))\n",
    "print('num not repatched connections ' + str(repatch.count('no')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repatched_cons_df = con_screen_df[con_screen_df['repatch'] == 'yes']\n",
    "repatched_cons_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_IDs, pre_IDs_repatch, post_IDs_repatch = [], [], []\n",
    "for m, pre_cell in enumerate(repatched_cons_df.pre_chan_IDs):\n",
    "    post_cell = repatched_cons_df.post_chan_IDs[m]\n",
    "    \n",
    "    cell_ID_pre = df_all_repatched['cell_IDs'].loc[df_all_repatched.temp_IDs == pre_cell].values[0]\n",
    "    cell_ID_post = df_all_repatched['cell_IDs'].loc[df_all_repatched.temp_IDs == post_cell].values[0]\n",
    "\n",
    "    pre_IDs_repatch.append(cell_ID_pre)\n",
    "    post_IDs_repatch.append(cell_ID_post)\n",
    "    con_IDs.append(cell_ID_pre + 'to' + cell_ID_post[-1])\n",
    "\n",
    "repatched_cons_df['connection_ID'] = con_IDs\n",
    "repatched_cons_df['pre_chan_IDs'] = pre_IDs_repatch\n",
    "repatched_cons_df['post_chan_IDs'] = post_IDs_repatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_repatched_cells, duplicates = repatch_duplicates(repatched_cons_df, 'connection_ID')\n",
    "\n",
    "# for con in not_repatched_connections:\n",
    "#     repatched_cons_df = repatched_cons_df.drop(repatched_cons_df.index[repatched_cons_df['connection_ID'] == con])     \n",
    "# repatched_cons_df.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each non-repeating connection\n",
    "# fill in excel with 'new' or 'disappearing'\n",
    "\n",
    "con = ''\n",
    "\n",
    "df_part = repatched_cons_df.loc[repatched_cons_df['connection_ID'] == con]\n",
    "fn = df_part.filename.values[0]\n",
    "OP = df_part.OP.values[0]\n",
    "patcher = df_part.patcher.values[0]\n",
    "slic = df_part.slice.values[0]\n",
    "\n",
    "work_dir, filenames, indices_dict, slice_names = sort.get_OP_metadata(HUMAN_DIR, OP, patcher, 'old')\n",
    "con_screen_json = sort.get_json_meta_connect_all(HUMAN_DIR, OP, patcher)[0]\n",
    "\n",
    "slic_indx_D1 = con_screen_json['slices'].index(slic)\n",
    "try:\n",
    "    slic_indx_D2 = con_screen_json['slices'].index(slic + '_D2')\n",
    "except:\n",
    "    slic_indx_D2 = con_screen_json['slices'].index(slic[:2])\n",
    "active_chans_D1 = con_screen_json['active_chans'][slic_indx_D1]\n",
    "active_chans_D2 = con_screen_json['active_chans'][slic_indx_D2]\n",
    "fn_2 = filenames[con_screen_json['con_screen_file'][slic_indx_D2]]\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "funcs_plotting_raw_traces.plot_con_screen_all(work_dir + fn, active_chans_D1)\n",
    "funcs_plotting_raw_traces.plot_con_screen_all(work_dir + fn_2, active_chans_D2)\n",
    "%matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '21d10035.abf'\n",
    "work_dir = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/data/human/data_verji/OP211209/'\n",
    "\n",
    "funcs_plotting_raw_traces.plot_con_screen_all(work_dir + fn, [1,2,4,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repatched_cons_df.to_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_connections_with_comments.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare collected to intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repatched_cons_collected = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_connections_collected_from_analyzed_folders.xlsx')\n",
    "collected_repatched = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_single_cells.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary ID for repatched cells, to match the one from the connections df\n",
    "temp_IDs_repatched_cells = []\n",
    "for g, op in enumerate(collected_repatched.OP):\n",
    "    slic = collected_repatched.slice.iloc[g]\n",
    "    chan = str(int(collected_repatched.chan.iloc[g]))\n",
    "    temp_IDs_repatched_cells.append(op[2:] + slic  + chan)\n",
    "\n",
    "collected_repatched['temp_ID'] = temp_IDs_repatched_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp pre and post cell IDs\n",
    "pre_cell_IDs, post_cell_IDs = [], []\n",
    "for f, pre_chan in enumerate(repatched_cons_collected.chan_pre):\n",
    "    op = repatched_cons_collected.OP.iloc[f][2:]\n",
    "    slic = repatched_cons_collected.slice.iloc[f]\n",
    "    post_chan = repatched_cons_collected.chan_post.iloc[f]\n",
    "\n",
    "    pre_cell_IDs.append(op + slic + str(int(pre_chan)))\n",
    "    post_cell_IDs.append(op + slic + str(int(post_chan)))\n",
    "\n",
    "# checking for mistakes\n",
    "repatches = []\n",
    "for d, pre_cell in enumerate(pre_cell_IDs):\n",
    "    post_cell = post_cell_IDs[d]\n",
    "    if pre_cell in temp_IDs_repatched_cells and post_cell in temp_IDs_repatched_cells:\n",
    "        repatches.append('yes')\n",
    "    else:\n",
    "        repatches.append('no')\n",
    "\n",
    "print('Number of not repatched cells: ' + str(repatches.count('no')))\n",
    "\n",
    "drop_indices = [index for index, value in enumerate(repatches) if value == 'no']\n",
    "\n",
    "# drop from the list\n",
    "pre_cell_IDs = [item for index, item in enumerate(pre_cell_IDs) if index not in drop_indices]\n",
    "post_cell_IDs = [item for index, item in enumerate(post_cell_IDs) if index not in drop_indices]\n",
    "\n",
    "# drop from the dataframe\n",
    "repatched_cons_collected = repatched_cons_collected.drop(drop_indices)\n",
    "repatched_cons_collected.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create true connection IDs\n",
    "con_IDs_new = []\n",
    "for p, pre_cell in enumerate(pre_cell_IDs):\n",
    "    post_cell = post_cell_IDs[p]\n",
    "\n",
    "    pre_cell_true_ID = collected_repatched['cell_IDs'][collected_repatched['temp_ID'] == pre_cell].values[0]\n",
    "    post_cell_true_ID = collected_repatched['cell_IDs'][collected_repatched['temp_ID'] == post_cell].values[0][-1]\n",
    "\n",
    "    # con_IDs_new.append()\n",
    "    con_IDs_new.append(pre_cell_true_ID + 'to' + post_cell_true_ID[-1])\n",
    "\n",
    "repatched_cons_collected['con_IDs_new'] = con_IDs_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repatched_cons_collected.to_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_connections_collected_from_analyzed_folders.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the two connections tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_connections_from_folders, all_cons_VC =  get_results.collect_connections_df()\n",
    "# all_connections_from_folders = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/connectivity/2024-12-09_connectivity.xlsx')\n",
    "# repatch_con_screen_from_tables = all_connections_from_folders[all_connections_from_folders['repatch'] == 'yes']\n",
    "repatched_cons_collected = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_connections_with_comments.xlsx')\n",
    "repatch_con_screen_from_tables = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/repatched_connections_collected_from_analyzed_folders.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repatched_cons_collected.reset_index(drop = True)\n",
    "drop_indices = []\n",
    "for h, comment in enumerate(repatched_cons_collected.comment):\n",
    "    if isinstance(comment, float):\n",
    "        continue\n",
    "    if 'exclude' in comment:\n",
    "        drop_indices.append(h)\n",
    "\n",
    "for indx in drop_indices:\n",
    "    repatched_cons_collected = repatched_cons_collected.drop(indx)     \n",
    "repatched_cons_collected.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_repatched_cells, duplicates = repatch_duplicates(repatched_cons_collected, 'connection_ID')\n",
    "for con in not_repatched_cells:\n",
    "    print(repatched_cons_collected.comment[repatched_cons_collected.connection_ID == con])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_from_tables = set(repatch_con_screen_from_tables.con_IDs_new)\n",
    "cons_from_comparison_with_intrinsic = set(repatched_cons_collected.connection_ID)\n",
    "\n",
    "in_tables_not_in_comparison = list(cons_from_tables - cons_from_comparison_with_intrinsic)\n",
    "in_comparison_not_in_collected = list(cons_from_comparison_with_intrinsic - cons_from_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(in_tables_not_in_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_add = pd.DataFrame()\n",
    "for con in in_comparison_not_in_collected:\n",
    "    con_data = repatched_cons_collected[repatched_cons_collected.connection_ID == con]\n",
    "    data_to_add = pd.concat([data_to_add[:], con_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse extra set of data\n",
    "\n",
    "HUMAN_DIR = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/data/human/'\n",
    "\n",
    "con_data = pd.DataFrame(columns = ['OP', 'fn', 'slice', 'day', 'connection_ID', 'repatch', 'treatment', \n",
    "'hrs_after_OP', 'hrs_incubation','chan_pre', 'chan_post', 'Vm pre', 'Vm post', \n",
    "'Amp 1','Amp 2','Amp 3', 'Amp 4',\t'Lat1',\t'Lat2',\t'Lat3',\t'Lat4', 'num excluded swps', 'comments'])\n",
    "\n",
    "exclude = ''\n",
    "for q, fn in enumerate(data_to_add.filename):\n",
    "    OP = data_to_add.OP.iloc[q]\n",
    "    patcher = data_to_add.patcher.iloc[q]\n",
    "    work_dir, filenames, indices_dict, slice_names = sort.get_OP_metadata(HUMAN_DIR, OP, patcher, 'old')\n",
    "    con_screen_file = work_dir + fn\n",
    "\n",
    "    pre_cell = data_to_add.pre_chans.iloc[q]\n",
    "    post_cell = data_to_add.post_chans.iloc[q]\n",
    "\n",
    "    pre_signal, es, vm_pre = con_param.presynaptic_screen(con_screen_file, pre_cell)\n",
    "    post_signal, vm_post = con_param.postsynaptic_screen(con_screen_file, post_cell, es)\n",
    "    if (np.array(vm_post)).size == 0:\n",
    "        print('QC not passed!!')\n",
    "        exclude = 'all'\n",
    "        es2 = []\n",
    "        post_signal, vm_post = con_param.postsynaptic_screen(con_screen_file, post_cell, es2)\n",
    "        continue\n",
    "    mean_pre, mean_post, pre_window, post_window, preAPs_shifted, preAPs = \\\n",
    "        con_param.get_analysis_window(pre_signal, post_signal)\n",
    "    pre_signal, post_signal = con_param.remove_sweeps_with_POSTsynAPs(pre_signal, post_signal, preAPs)\n",
    "    post_peaks = con_param.find_postsynaptic_peaks(post_window, preAPs_shifted)\n",
    "    post_local_baseline = con_param.get_psp_baselines(post_window,preAPs_shifted)\n",
    "    onsets = con_param.get_onsets(preAPs_shifted, post_window, post_peaks, post_local_baseline)\n",
    "    latency = con_param.latencies(onsets, preAPs_shifted)\n",
    "    amps = con_param.get_amps(post_peaks, post_local_baseline)\n",
    "\n",
    "    df_add = pd.DataFrame({'OP': OP, 'fn': fn, 'slice': slic, 'day':data_to_add.day.iloc[q], \n",
    "                           'treatment': data_to_add.treatment.iloc[q], \n",
    "    'connection_ID' : data_to_add.connection_ID.iloc[q]\t,\n",
    "    'chan_pre': pre_cell, 'chan_post': post_cell, 'Vm pre' :vm_pre, 'Vm post': vm_post,\n",
    "    'Amp 1': amps[0], 'Amp 2': amps[1],\t'Amp 3': amps[2],\t'Amp 4': amps[3],\t\n",
    "        'Lat1': latency[0][0],\t'Lat2' : latency[1][0],\t'Lat3': latency[2][0],\t'Lat4': latency[3][0], \n",
    "    'num excluded swps': len(es), 'comments': exclude}, index=[0])\n",
    "    con_data = pd.concat([con_data.loc[:], df_add]).reset_index(drop=True)\n",
    "\n",
    "    funcs_plotting_raw_traces.plot_connection_window(con_screen_file, pre_cell, post_cell, pre_window, \\\n",
    "            post_window, preAPs_shifted, post_signal, onsets, preAPs, post_peaks, post_local_baseline)\n",
    "    funcs_plotting_raw_traces.plot_post_cell(con_screen_file, pre_cell, post_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to df\n",
    "repatch_con_screen_from_tables = pd.concat([repatch_con_screen_from_tables.loc[:],con_data.loc[:]]).reset_index(drop=True)\n",
    "repatch_con_screen_from_tables = repatch_con_screen_from_tables.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_hrs_incubation\n",
    "df = repatched_cons_collected # repatched_cons_collected\n",
    "\n",
    "OP_hrs_inc_dict = {}\n",
    "for OP in repatched_cons_collected.OP.unique():\n",
    "    hrs_inc = repatched_cons_collected.hrs_incubation[(repatched_cons_collected.OP == OP) & \\\n",
    "                                                            (repatched_cons_collected.hrs_incubation != 0)]\n",
    "    if len(hrs_inc) == 0:\n",
    "        OP_hrs_inc_dict[OP] = ''\n",
    "    else:\n",
    "        OP_hrs_inc_dict[OP] = int(hrs_inc.values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repatch_con_screen_from_tables.to_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/lab_seminar_Dec_24/all_analyzed_connection_complete.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ephys_analysis.funcs_plot_intrinsic_props as pl_intr\n",
    "import pandas as pd\n",
    "\n",
    "def QC_connectivity_df(df):\n",
    "    mask = (df['Vm pre'] < -40 ) & (df['Vm post'] < -40)\n",
    "        # (df['Amp 1'] > 0) &  (df['Amp 2'] > 0 )   & \\\n",
    "        #     (df['Amp 3'] > 0 ) &  (df['Amp 4'] > 0)\n",
    "    df = df.loc[mask, :]\n",
    "    return df\n",
    "\n",
    "DEST_DIR = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/lab_seminar_Dec_24/'\n",
    "con_screen_df = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/lab_seminar_Dec_24/all_repatched_connection_complete.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only adults\n",
    "con_screen_df = con_screen_df[con_screen_df.patient_age > 12]\n",
    "con_screen_df = con_screen_df[(con_screen_df.hrs_incubation == 0) |\n",
    "                                (con_screen_df.hrs_incubation > 15)].copy()\n",
    "repa, duplic = repatch_duplicates(con_screen_df, 'con_IDs_new')\n",
    "\n",
    "for con in repa:\n",
    "    drop_indx = con_screen_df[con_screen_df['con_IDs_new'] == con].index\n",
    "    con_screen_cleaned = con_screen_df.drop(drop_indx)\n",
    "con_screen_cleaned.reset_index(inplace = True)\n",
    "con_screen_df = con_screen_cleaned\n",
    "con_screen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_color_dict = pl_intr.get_op_color_dict(con_screen_df)\n",
    "\n",
    "# con_screen_df['Amp 1'] = con_screen_df['Amp 1'].fillna(0)\n",
    "# con_screen_df['Amp 2'] = con_screen_df['Amp 2'].fillna(0)\n",
    "# con_screen_df['Amp 3'] = con_screen_df['Amp 3'].fillna(0)\n",
    "# con_screen_df['Amp 4'] = con_screen_df['Amp 4'].fillna(0)\n",
    "# con_screen_df.columns[con_screen_df.isna().any()].tolist()\n",
    "\n",
    "connect_QC_passed = QC_connectivity_df(con_screen_df)\n",
    "\n",
    "repatch_connect = pl_intr.get_repatch_connectivity_df(connect_QC_passed)\n",
    "# how to deal with disappearing connections\n",
    "repatch_connect.fillna(0, inplace = True) #fill missing values with 0\n",
    "pl_intr.plot_connect_amplitude(repatch_connect, 'repatch_IC', \\\n",
    "    op_color_dict ,'con_IDs_new' ,'amp', DEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect slice connections data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cons_IC, all_cons_VC =  get_results.collect_connections_df()\n",
    "all_cons_IC['Amp 1'] = all_cons_IC['Amp 1'].fillna(0)\n",
    "all_cons_IC['Amp 2'] = all_cons_IC['Amp 2'].fillna(0)\n",
    "all_cons_IC['Amp 3'] = all_cons_IC['Amp 3'].fillna(0)\n",
    "all_cons_IC['Amp 4'] = all_cons_IC['Amp 4'].fillna(0)\n",
    "all_cons_IC.columns[all_cons_IC.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cons_IC = all_cons_IC[all_cons_IC.OP != 'OP201020'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_age = []\n",
    "for i, op in enumerate(all_cons_IC.OP):\n",
    "    patient_age.append(op_age_dict[op])\n",
    "\n",
    "all_cons_IC['patient_age'] = patient_age \n",
    "all_cons_IC = all_cons_IC[all_cons_IC['patient_age'] > 12]\n",
    "\n",
    "all_cons_IC.hrs_incubation.astype(int)\n",
    "all_cons_IC = all_cons_IC[(all_cons_IC.hrs_incubation == 0) |\n",
    "                                (all_cons_IC.hrs_incubation > 15)].copy()\n",
    "\n",
    "all_cons_IC.hrs_incubation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_QC_passed = pl_intr.get_QC_connectivity_df(all_cons_IC)\n",
    "op_color_dict = pl_intr.get_op_color_dict(all_cons_IC)\n",
    "connect_slice = connect_QC_passed[connect_QC_passed['repatch'] == 'no']\n",
    "pl_intr.plot_connect_amplitude(df = connect_slice, data_type = 'all_IC', \\\n",
    "    op_color_dict = op_color_dict , con_ID_col = 'connection_ID' ,results_ ='amp', \\\n",
    "        destination_dir =DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect_slice.to_csv('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/lab_seminar_Dec_24/for_R/slice_connections_adult.csv')\n",
    "# repatch_connect.to_csv('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/lab_seminar_Dec_24/for_R/repatch_connections_adult.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
